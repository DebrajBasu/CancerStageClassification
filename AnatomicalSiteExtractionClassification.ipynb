{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatomical site extraction from QUICKUMLS algorithm output dataset: workaround and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample scripts\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ast\n",
    "data_dir = os.getcwd()\n",
    "#print(data_dir)\n",
    "cohort_df = pd.read_csv(data_dir + '/data/chrtDf.csv')\n",
    "Pnotes_df = pd.read_pickle('PnotesNoDuplicate.pkl')\n",
    "RadPath_df = pd.read_pickle('RadPathNoDuplicate.pkl')\n",
    "SurgPath_df = pd.read_pickle('SurgPathNoDuplicate.pkl')\n",
    "cohort_df.rename(columns =  {'tnm_mixed_stage_desc' : 'levels'},inplace= True)\n",
    "cohort_df = cohort_df.loc[cohort_df['pat_id']!='NOPE']\n",
    "pat_count = cohort_df.groupby('pat_id').size().sort_values(ascending=False)\n",
    "# single record seperation\n",
    "patsWithOne = pat_count.loc[pat_count == 1]\n",
    "chrtDfOne = cohort_df.loc[cohort_df['pat_id'].isin(list(patsWithOne.index))].reset_index()\n",
    "\n",
    "#Remove records with no labels or missing labels\n",
    "\n",
    "chrtDfOne.where(((chrtDfOne['levels'] != 'Unknown') & (chrtDfOne['levels'] != 'Missing')& (chrtDfOne['levels'] != 'Not Applicable')), inplace = True )\n",
    "chrtDfOne=chrtDfOne.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for any missing levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrtDfOne.groupby('levels').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for the field that contains QUICKUMLS output from the free texts in Pnotes, RadPath and SurgPath \n",
    "## \"nlp_text_qu_ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample database info from RadPath \n",
    "RadPath_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Drop any null value in 'nlp_text_qu_ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurgPath_df.dropna(subset = ['nlp_text_qu_ner'], inplace = True)\n",
    "RadPath_df.dropna(subset = ['nlp_text_qu_ner'], inplace = True)\n",
    "Pnotes_df.dropna(subset = ['nlp_text_qu_ner'], inplace = True)\n",
    "RadPath_df = RadPath_df[RadPath_df['nlp_text_qu_ner']!='[]']\n",
    "RadPath_df.reset_index(inplace = True)\n",
    "Pnotes_df = Pnotes_df[Pnotes_df['nlp_text_qu_ner']!='[]']\n",
    "Pnotes_df.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test purpose code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pat_id = 369\n",
    "text =SurgPath_df.loc[pat_id, 'nlp_text_qu_ner']\n",
    "d = ast.literal_eval(text)\n",
    "Testframe = pd.DataFrame.from_dict(d)\n",
    "corpus= Testframe[Testframe['semtypestring'] == 'T033']['ngram'].tolist()\n",
    "pat_id = SurgPath_df.loc[877, 'pat_id']\n",
    "print(corpus)\n",
    "#corpus = [l for l in corpus if len(l.split(' ')) >= 2]\n",
    "if corpus != []:\n",
    "# #corpus = ['This is the first document.','This document is the second document.','And this is the third one.',\\\n",
    "#           'Is this the first document?']\n",
    "    #vectorizer = CountVectorizer()\n",
    "#     print(corpus)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(X.toarray())\n",
    "#     print(X.toarray(),axis =0).max())\n",
    "    print(vectorizer.get_feature_names()[np.sum(X.toarray(),axis =0).argmax()])\n",
    "else:\n",
    "    print('Empty corpus')\n",
    "    \n",
    "    \n",
    "chrtDfOne[chrtDfOne['pat_id']== pat_id][['levels', 'site_group', 'vital_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List the anatomical sites mentioned in the main cohort (chrtDfOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find any NULL site group and remove from the list\n",
    "chrtDfOne.groupby('site_group').size()\n",
    "\n",
    "chrtDfOne['site_group'].isnull().sum()\n",
    "chrtDfOne = chrtDfOne.dropna(subset = ['site_group']).reset_index(drop= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign the site group in to a list for list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LUNG/BRONCHUS-NON SM CELL',\n",
       " 'BREAST',\n",
       " \"NON-HODGKIN'S LYMPHOMA\",\n",
       " 'PROSTATE',\n",
       " 'CORPUS UTERI',\n",
       " 'BLADDER',\n",
       " 'PANCREAS',\n",
       " 'OVARY',\n",
       " 'LUNG/BRONCHUS-SMALL CELL',\n",
       " 'STOMACH',\n",
       " \"HODGKIN'S DISEASE\",\n",
       " 'UTERUS NOS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SiteList =chrtDfOne['site_group'].unique().tolist()\n",
    "SiteList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The performance based on different site group\n",
    "## - Creating dataframes for each site using dict comprehension\n",
    "## - Access each dataframe by keys from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns of interest\n",
    "col2use = ['pat_id', 'site_group', 'histology_desc', 'levels']\n",
    "# Use dict comprehension to create dfs  for each site group\n",
    "dfs_sitegroups = {'chrt_' + str(site[0:8]):chrtDfOne[chrtDfOne['site_group']== site][col2use].reset_index(drop= True) for site in SiteList}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the free text reports \n",
    "## FROM SURGPATH : using countvectorizer and TF_IDF vectorizer to find the maximum occurance of a word from the list of words in the site report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3388, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_TFIDF = TfidfVectorizer()\n",
    "vectorizer_CV = CountVectorizer()\n",
    "df_anatomical_merged = pd.DataFrame({'pat_id': [], 'anatomical site_CV(T023)': [], 'anatomical site_TFIDF(T023)': []})\n",
    "#for i in range(1,200):\n",
    "for i in range(len(SurgPath_df.index)):\n",
    "    text = SurgPath_df.iloc[i].nlp_text_qu_ner\n",
    "    d = ast.literal_eval(text)\n",
    "    Testframe = pd.DataFrame.from_dict(d)\n",
    "    \n",
    "    corpus_T023 = Testframe[Testframe['semtypestring'] == 'T023']['ngram'].tolist()\n",
    "    \n",
    "    #corpus_T023 = [l for l in corpus_T023 if len(l.split(' ')) <=2]\n",
    "    if (corpus_T023  != []):\n",
    "    \n",
    "        X_T023_CV = vectorizer_CV.fit_transform(corpus_T023)\n",
    "        X_T023_TFIDF = vectorizer_TFIDF.fit_transform(corpus_T023)\n",
    "        \n",
    "        max_ngram_T023_CV = vectorizer_CV.get_feature_names()[np.sum(X_T023_CV.toarray(),axis =0).argmax()]\n",
    "        max_ngram_T023_TFIDF = vectorizer_TFIDF.get_feature_names()[np.sum(X_T023_TFIDF.toarray(),axis =0).argmax()]\n",
    "        \n",
    "        df_anatomical_merged= df_anatomical_merged.append({'pat_id':SurgPath_df.iloc[i]['pat_id'], \\\n",
    "                                                               'anatomical site_CV(T023)': max_ngram_T023_CV, \\\n",
    "                                                               'anatomical site_TFIDF(T023)': max_ngram_T023_TFIDF}, ignore_index=True)\n",
    "            \n",
    "df_anatomical_merged.shape        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates based on anatomical site_TFIDF(T023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anatomical_merged_noDUP = df_anatomical_merged.drop_duplicates(subset=['pat_id', 'anatomical site_TFIDF(T023)'],keep='first')\n",
    "df_anatomical_merged_noDUP.reset_index( drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge anatomical site extraction from SURGpath with main cohort based on patient as the primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_breast = pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_BREAST'], on= 'pat_id')\n",
    "df_surg_merged_lungsnonSM = pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_LUNG/BRO'], on= 'pat_id')\n",
    "df_surg_merged_prostate= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_PROSTATE'], on= 'pat_id')\n",
    "df_surg_merged_bladder= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_BLADDER'], on= 'pat_id')\n",
    "df_surg_merged_ovary= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_OVARY'], on= 'pat_id')\n",
    "df_surg_merged_uterusNOS= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_UTERUS N'], on= 'pat_id')\n",
    "df_surg_merged_nonHD= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_NON-HODG'], on= 'pat_id')\n",
    "df_surg_merged_stomach= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_STOMACH'], on= 'pat_id')\n",
    "df_surg_merged_pancreas= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_PANCREAS'], on= 'pat_id')\n",
    "df_surg_merged_HD= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups[\"chrt_HODGKIN'\"], on= 'pat_id')\n",
    "df_surg_merged_lungsSM= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_LUNG/BRO'], on= 'pat_id')\n",
    "df_surg_merged_corpusUteri= pd.merge(df_anatomical_merged_noDUP , dfs_sitegroups['chrt_CORPUS U'], on= 'pat_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_breast['site_group'] = df_surg_merged_breast['site_group'].apply(lambda x: x.lower())\n",
    "df_surg_merged_breast['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_breast['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_breast.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_breast.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_breast.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_breast.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_breast.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_breast[df_surg_merged_breast['Contains (True/False)']==1])/len(df_surg_merged_breast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: lungs non SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_lungsnonSM['site_group'] = df_surg_merged_lungsnonSM['site_group'].apply(lambda x: x.lower())\n",
    "df_surg_merged_lungsnonSM['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_lungsnonSM['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_lungsnonSM.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_lungsnonSM.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_lungsnonSM.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_lungsnonSM.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_lungsnonSM.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_lungsnonSM[df_surg_merged_lungsnonSM['Contains (True/False)']==1])/len(df_surg_merged_lungsnonSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: prostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_prostate['site_group'] = df_surg_merged_prostate['site_group'].apply(lambda x: x.lower())\n",
    "df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_prostate['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_prostate.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_prostate.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_prostate.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_prostate.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_prostate.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_prostate[df_surg_merged_prostate['Contains (True/False)']==1])/len(df_surg_merged_prostate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: bladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_bladder['site_group'] = df_surg_merged_bladder['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_bladder['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_bladder.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_bladder.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_bladder.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_bladder.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_bladder.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_bladder[df_surg_merged_bladder['Contains (True/False)']==1])/len(df_surg_merged_bladder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: HODGKIN'S disease (HD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_HD['site_group'] = df_surg_merged_HD['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_HD['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_HD.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_HD.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_HD.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_HD.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_HD.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_HD[df_surg_merged_HD['Contains (True/False)']==1])/len(df_surg_merged_HD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: CORPUS UTERI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_corpusUteri['site_group'] = df_surg_merged_corpusUteri['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_corpusUteri['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_corpusUteri.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_corpusUteri.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_corpusUteri.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_corpusUteri.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_corpusUteri.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_corpusUteri[df_surg_merged_corpusUteri['Contains (True/False)']==1])/len(df_surg_merged_corpusUteri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: PANCREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_pancreas['site_group'] = df_surg_merged_pancreas['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_pancreas['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_pancreas.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_pancreas.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_pancreas.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_pancreas.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_pancreas.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_pancreas[df_surg_merged_pancreas['Contains (True/False)']==1])/len(df_surg_merged_pancreas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: STOMACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_stomach['site_group'] = df_surg_merged_stomach['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_stomach['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_stomach.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_stomach.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_stomach.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_stomach.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_stomach.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_stomach[df_surg_merged_stomach['Contains (True/False)']==1])/len(df_surg_merged_stomach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: OVARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_ovary['site_group'] = df_surg_merged_ovary['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_ovary['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_ovary.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_ovary.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_ovary.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_ovary.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_ovary.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_ovary[df_surg_merged_ovary['Contains (True/False)']==1])/len(df_surg_merged_ovary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: NON-HODGKIN'S LYMPHOMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_nonHD['site_group'] = df_surg_merged_nonHD['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_nonHD['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_nonHD.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_nonHD.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_nonHD.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_nonHD.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_nonHD.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_nonHD[df_surg_merged_nonHD['Contains (True/False)']==1])/len(df_surg_merged_nonHD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the ground truth and the outcome of site locations from the surgpath file: LUNG/BRONCHUS-SMALL CELL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_surg_merged_lungsSM['site_group'] = df_surg_merged_lungsSM['site_group'].apply(lambda x: x.lower())\n",
    "# df_surg_merged_prostate['Levenshtein distance'] = np.nan\n",
    "df_surg_merged_lungsSM['Contains (True/False)'] = np.nan\n",
    "import nltk\n",
    "for i in range(len(df_surg_merged_lungsSM.index)):\n",
    "\n",
    "# #     print((nltk.edit_distance(df_merged.iloc[i]['site_group'],df_merged.iloc[i]['anatomical site_TFIDF'] ))/len(df_merged.iloc[i]['site_group'])  )\n",
    "#     df_merged.loc[i,'Levenshtein distance']= nltk.edit_distance(df_merged.loc[i,'anatomical site_CV'] ,df_merged.loc[i,'site_group'])/len(df_merged.loc[i,'site_group'])\n",
    "# #     df_merged['Contains (True/False)'] = 1 if (df_merged.loc[i,'anatomical site_TFIDF'] in df_merged.loc[i,'site_group']) else 0 \n",
    "    if (df_surg_merged_lungsSM.loc[i,'anatomical site_TFIDF(T023)'] in df_surg_merged_lungsSM.loc[i,'site_group']):\n",
    "        \n",
    "        \n",
    "        df_surg_merged_lungsSM.loc[i,'Contains (True/False)'] = 1\n",
    "    else:\n",
    "        df_surg_merged_lungsSM.loc[i,'Contains (True/False)'] = 0\n",
    "len(df_surg_merged_lungsSM[df_surg_merged_lungsSM['Contains (True/False)']==1])/len(df_surg_merged_lungsSM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
