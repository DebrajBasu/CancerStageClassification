{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbasu/.local/share/virtualenvs/debraj_notebook-uSskSi2b/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# sample scripts\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ast\n",
    "data_dir = os.getcwd()\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#print(data_dir)\n",
    "cohort_df = pd.read_csv(data_dir + '/data/chrtDf.csv')\n",
    "Pnotes_df = pd.read_pickle('Pnotesfile.pickle')\n",
    "RadPath_df = pd.read_pickle('RadPathfile.pickle')\n",
    "SurgPath_df = pd.read_pickle('SurgPathfile.pickle')\n",
    "cohort_df.rename(columns =  {'tnm_mixed_stage_desc' : 'levels'},inplace= True)\n",
    "cohort_df = cohort_df.loc[cohort_df['pat_id']!='NOPE']\n",
    "pat_count = cohort_df.groupby('pat_id').size().sort_values(ascending=False)\n",
    "# single record seperation\n",
    "patsWithOne = pat_count.loc[pat_count == 1]\n",
    "chrtDfOne = cohort_df.loc[cohort_df['pat_id'].isin(list(patsWithOne.index))].reset_index()\n",
    "#Remove records with no labels or missing labels\n",
    "\n",
    "chrtDf = chrtDfOne[chrtDfOne.levels != 'Unknown']\n",
    "chrtDf = chrtDfOne[chrtDfOne.levels != 'Missing']\n",
    "chrtDf = chrtDfOne[chrtDfOne.levels != 'Not Applicable']\n",
    "chrtDf = chrtDfOne[chrtDfOne['gender'].notnull()]\n",
    "chrtDf = chrtDfOne[chrtDfOne['bmi'].notnull()]\n",
    "\n",
    "#stripping the subclass of cancer staging data; eg. 1A to 1\n",
    "chrtDf['levels'] = chrtDf['levels'].apply(lambda x: x[0])\n",
    "#print(text)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows that have no text or '[ ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14904, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RadPath_df.dropna(subset=['note_text'], inplace =True)\n",
    "RadPath_df = RadPath_df[RadPath_df['nlp_text_qu_ner']!='[]']\n",
    "RadPath_df.reset_index(inplace = True)\n",
    "RadPath_df.shape\n",
    "RadPath_df.reset_index(drop = True)\n",
    "RadPath_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK sentence tokenizer to find out average number of sentences in each note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.005233494363928"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RadSenLen =[]\n",
    "for i in RadPath_df.index:\n",
    "    text =RadPath_df.loc[i]['note_text']\n",
    "    doc = sent_tokenize(text)\n",
    "    RadSenLen.append(len(doc))\n",
    "# for i, token in enumerate(doc):\n",
    "#     print('-->Sentence %d: %s' % (i, token))\n",
    "np.mean(np.array(RadSenLen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns to RadPath data frame\n",
    "### Columns: number of sentences in the text, longest and shortest and average number of words in each sentence in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RadPath_df =RadPath_df.assign(**{'Number of sentences': np.nan, 'Longest sentence length (words)': np.nan, \\\n",
    "                                 'Shortest sentence length(words)': np.nan, \\\n",
    "                    'average sentence length(words)':np.nan})\n",
    "# RadPath_df.assign(Number_of_sentences = np.nan, Longest_sentence_length = np.nan, Shortest_sentence_length = np.nan, \\\n",
    "#                    Average_sentence_length= np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all the sentence lengths in the radpath text notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Number_sentence(text):\n",
    "    return len(sent_tokenize(text))\n",
    "\n",
    "RadPath_df['Number of sentences'] = RadPath_df['note_text'].apply(Number_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add statistics for each note text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from statistics import mean\n",
    "def word_count(doc):\n",
    "    lenWordHolder =[]\n",
    "    for i, token in enumerate(doc):\n",
    "        \n",
    "        lenWordHolder.append(len(word_tokenize(token)))\n",
    "    return lenWordHolder\n",
    "    \n",
    "def max_length(text):\n",
    "    doc = sent_tokenize(text)\n",
    "    len_word = word_count(doc)\n",
    "    #print(max(len_word))\n",
    "    return max(len_word)\n",
    "\n",
    "def min_length(text):\n",
    "    doc = sent_tokenize(text)\n",
    "    len_word = word_count(doc)\n",
    "#     print(min(len_word))\n",
    "#     print('\\n')\n",
    "#     print(doc)\n",
    "    return min(len_word)\n",
    "    \n",
    "def avg_length(text):\n",
    "    doc = sent_tokenize(text)\n",
    "    len_word = word_count(doc)\n",
    "    return mean(len_word)\n",
    "        \n",
    "RadPath_df['Longest sentence length (words)'] = RadPath_df['note_text'].apply(max_length)\n",
    "RadPath_df['Shortest sentence length(words)'] = RadPath_df['note_text'].apply(min_length)\n",
    "RadPath_df['average sentence length(words)'] = RadPath_df['note_text'].apply(avg_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12598,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RadPath_df['note_text'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RadPath_analysis = RadPath_df[['pat_id','result_time','note_text', 'Number of sentences','Longest sentence length (words)',\\\n",
    "                               'Shortest sentence length(words)', 'average sentence length(words)', 'nlp_text_qu_ner' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RadPath_analysis.hist(column= 'Number of sentences',bins= 50, grid=True, figsize=(12,8), color='red', zorder=2, rwidth=0.9 )\n",
    "#RadPath_analysis['Number of sentences'].hist(bins =50)\n",
    "RadPath_analysis['Number of sentences'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Around 16% of the note texts have only one sentence. We will examine how important are these one-sentence notes for cancer-related information extraction (e.g. stage, grade, anatomical site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXSklEQVR4nO3df7DddX3n8efLgNgRW8BkmRAwUBvXxZ1tZG+RrraiVgjszgY76oI7knXZjW6D1Y7uiGWnoC4zOl2ldQaZRkkBR2Vp0ZJaLKYIsrpFcsEQCIi5IikJSKJBNOs2XeC9f5zPHU9zfyf33gP3+3zMnDnf8/7+OJ/vd859ne/5nO/53FQVkqRueN6gGyBJmj+GviR1iKEvSR1i6EtShxj6ktQhhw26AZNZvHhxnXjiiYNuhiQ9p9x1110/rKol4817Vof+iSeeyPDw8KCbIUnPKUl2TDRvyu6dJC9IcmeSe5JsS/KhVr86yfeTbGm3la2eJJ9MMpJka5JT+ra1Jsn2dlszC/smSZqB6Zzp7wdeX1X7khwOfCPJV9q8/1pVf37A8mcBK9rtVcCVwKuSHANcAgwBBdyVZGNVPTEbOyJJmtqUZ/rVs689PLzdJvsZ72rg2rbeHcBRSZYCZwKbqmpvC/pNwKpDa74kaSamdfVOkkVJtgC76QX3t9qsy1oXzuVJjmi1ZcAjfavvbLWJ6gc+19okw0mG9+zZM7O9kSRNalqhX1VPV9VK4Hjg1CT/HPgg8HLg14BjgA/MRoOqan1VDVXV0JIl4375LEk6SDO6Tr+qfgzcCqyqqsdaF85+4E+BU9tiu4AT+lY7vtUmqkuS5sl0rt5ZkuSoNv0LwBuB77R+epIEOAe4r62yETi/XcVzGvBkVT0G3AyckeToJEcDZ7SaJGmeTOfqnaXANUkW0XuTuL6qvpzka0mWAAG2AO9qy98EnA2MAD8D3gFQVXuTfATY3Jb7cFXtnbU9kSRNKc/m8fSHhobKH2dJ0swkuauqhsab96z+Re6huuKKz/Poo/vG1I877kjWrXvbAFokSYO1oEP/0Uf3sXz52jH1HTvWD6A1kjR4jrIpSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHXIlKGf5AVJ7kxyT5JtST7U6icl+VaSkST/M8nzW/2I9nikzT+xb1sfbPUHk5w5Z3slSRrXdM709wOvr6pfBVYCq5KcBnwMuLyqfgV4ArigLX8B8ESrX96WI8nJwLnAK4BVwKeSLJrFfZEkTWHK0K+efe3h4e1WwOuBP2/1a4Bz2vTq9pg2/w1J0urXVdX+qvo+MAKcOhs7IUmanmn16SdZlGQLsBvYBHwP+HFVPdUW2Qksa9PLgEcA2vwngRf318dZp/+51iYZTjK8Z8+eGe+QJGli0wr9qnq6qlYCx9M7O3/5XDWoqtZX1VBVDS1ZsmSunkaSOmlGV+9U1Y+BW4FfB45KclibdTywq03vAk4AaPN/CfhRf32cdSRJ82A6V+8sSXJUm/4F4I3AA/TC/81tsTXAjW16Y3tMm/+1qqpWP7dd3XMSsAK4c5b2Q5I0DYdNvQhLgWvalTbPA66vqi8nuR+4Lsl/B74NXNWWvwr4bJIRYC+9K3aoqm1JrgfuB54C1lXV07O7O5KkyUwZ+lW1FXjlOPWHGOfqm6r6e+AtE2zrMuCymTdTkjQb/EWuJHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHTKd8fQ744orPs+jj+4bUz/uuCNZt+5tA2iRJM0uQ7/Po4/uY/nytWPqO3asH0BrJGn22b0jSR1i6EtShxj6ktQhhr4kdYihL0kdMmXoJzkhya1J7k+yLcl7Wv3SJLuSbGm3s/vW+WCSkSQPJjmzr76q1UaSXDQ3uyRJmsh0Ltl8CnhfVd2d5EXAXUk2tXmXV9X/6F84ycnAucArgOOAv0nysjb7CuCNwE5gc5KNVXX/bOyIJGlqU4Z+VT0GPNamf5rkAWDZJKusBq6rqv3A95OMAKe2eSNV9RBAkuvasoa+JM2TGfXpJzkReCXwrVa6MMnWJBuSHN1qy4BH+lbb2WoT1Q98jrVJhpMM79mzZybNkyRNYdqhn+RI4AbgvVX1E+BK4KXASnqfBD4+Gw2qqvVVNVRVQ0uWLJmNTUqSmmkNw5DkcHqB/7mq+iJAVT3eN//TwJfbw13ACX2rH99qTFKXJM2D6Vy9E+Aq4IGq+kRffWnfYm8C7mvTG4FzkxyR5CRgBXAnsBlYkeSkJM+n92XvxtnZDUnSdEznTP/VwNuBe5NsabXfB85LshIo4GHgnQBVtS3J9fS+oH0KWFdVTwMkuRC4GVgEbKiqbbO2J5KkKU3n6p1vABln1k2TrHMZcNk49ZsmW0+SNLf8Ra4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1yJShn+SEJLcmuT/JtiTvafVjkmxKsr3dH93qSfLJJCNJtiY5pW9ba9ry25OsmbvdkiSNZzpn+k8B76uqk4HTgHVJTgYuAm6pqhXALe0xwFnAinZbC1wJvTcJ4BLgVcCpwCWjbxSSpPkxZehX1WNVdXeb/inwALAMWA1c0xa7BjinTa8Grq2eO4CjkiwFzgQ2VdXeqnoC2ASsms2dkSRNbkZ9+klOBF4JfAs4tqoea7N+ABzbppcBj/SttrPVJqof+BxrkwwnGd6zZ89MmidJmsK0Qz/JkcANwHur6if986qqgJqNBlXV+qoaqqqhJUuWzMYmJUnNtEI/yeH0Av9zVfXFVn68ddvQ7ne3+i7ghL7Vj2+1ieqSpHkynat3AlwFPFBVn+ibtREYvQJnDXBjX/38dhXPacCTrRvoZuCMJEe3L3DPaDVJ0jw5bBrLvBp4O3Bvki2t9vvAR4Hrk1wA7ADe2ubdBJwNjAA/A94BUFV7k3wE2NyW+3BV7Z2NnZAkTc+UoV9V3wAywew3jLN8Aesm2NYGYMNMGihJmj3+IleSOsTQl6QOMfQlqUMMfUnqkOlcvbPgDA9v4eKL149Tv4/lywfQIEmaJ50M/X37nmH58rVj6rfd9q4BtEaS5o/dO5LUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHTBn6STYk2Z3kvr7apUl2JdnSbmf3zftgkpEkDyY5s6++qtVGklw0+7siSZrKdM70rwZWjVO/vKpWtttNAElOBs4FXtHW+VSSRUkWAVcAZwEnA+e1ZSVJ82jKf5dYVbcnOXGa21sNXFdV+4HvJxkBTm3zRqrqIYAk17Vl7595kyVJB+tQ+vQvTLK1df8c3WrLgEf6ltnZahPVx0iyNslwkuE9e/YcQvMkSQc62H+MfiXwEaDa/ceB/zgbDaqq9cB6gKGhoZqNbR6q4eEtXHzx+jH14447knXr3jaAFknSwTmo0K+qx0enk3wa+HJ7uAs4oW/R41uNSerPevv2PcPy5WvH1HfsGPtGIEnPZgfVvZNkad/DNwGjV/ZsBM5NckSSk4AVwJ3AZmBFkpOSPJ/el70bD77ZkqSDMeWZfpIvAKcDi5PsBC4BTk+ykl73zsPAOwGqaluS6+l9QfsUsK6qnm7buRC4GVgEbKiqbbO9M5KkyU3n6p3zxilfNcnylwGXjVO/CbhpRq2TJM0qf5ErSR1i6EtShxj6ktQhB3udvvD6fUnPPYb+IfD6fUnPNXbvSFKHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR0yZegn2ZBkd5L7+mrHJNmUZHu7P7rVk+STSUaSbE1ySt86a9ry25OsmZvdkSRNZjpn+lcDqw6oXQTcUlUrgFvaY4CzgBXttha4EnpvEsAlwKuAU4FLRt8oJEnzZ8rQr6rbgb0HlFcD17Tpa4Bz+urXVs8dwFFJlgJnApuqam9VPQFsYuwbiSRpjh1sn/6xVfVYm/4BcGybXgY80rfczlabqD5GkrVJhpMM79mz5yCbJ0kazyF/kVtVBdQstGV0e+uraqiqhpYsWTJbm5UkcfCh/3jrtqHd7271XcAJfcsd32oT1SVJ8+hgQ38jMHoFzhrgxr76+e0qntOAJ1s30M3AGUmObl/gntFqkqR5dNhUCyT5AnA6sDjJTnpX4XwUuD7JBcAO4K1t8ZuAs4ER4GfAOwCqam+SjwCb23IfrqoDvxxeMIaHt3DxxevH1I877kjWrXvbAFokST1Thn5VnTfBrDeMs2wB6ybYzgZgw4xa9xy1b98zLF++dkx9x46xbwSSNJ/8Ra4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CFT/jhLs8df6koaNEN/HvlLXUmDZveOJHWIZ/rPAnb7SJovhv6zgN0+kuaL3TuS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUoccUugneTjJvUm2JBlutWOSbEqyvd0f3epJ8skkI0m2JjllNnZAkjR9s3Gm/7qqWllVQ+3xRcAtVbUCuKU9BjgLWNFua4ErZ+G5JUkzMBfDMKwGTm/T1wC3AR9o9WurqoA7khyVZGlVPTYHbVgQHJNH0mw71NAv4KtJCviTqloPHNsX5D8Ajm3Ty4BH+tbd2Wr/KPSTrKX3SYCXvOQlh9i85zbH5JE02w419F9TVbuS/BNgU5Lv9M+sqmpvCNPW3jjWAwwNDc1o3a6Y6BMA+ClA0uQOKfSrale7353kS8CpwOOj3TZJlgK72+K7gBP6Vj++1TRDE30CAD8FSJrcQX+Rm+SFSV40Og2cAdwHbATWtMXWADe26Y3A+e0qntOAJ+3Pl6T5dShn+scCX0oyup3PV9VfJ9kMXJ/kAmAH8Na2/E3A2cAI8DPgHYfw3JKkg3DQoV9VDwG/Ok79R8AbxqkXsO5gn0+SdOj8Ra4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CFzMbSyBsjhmCVNxtBfYByOWdJk7N6RpA4x9CWpQ+ze6Qj7+iWBod8Z9vVLArt3JKlTDH1J6hBDX5I6xNCXpA4x9CWpQ7x6p+O8lFPqFkO/47yUU+oWu3ckqUPm/Uw/ySrgj4FFwGeq6qPz3QZNzW4faWGa19BPsgi4AngjsBPYnGRjVd0/n+3Q1Cbq9rnhht/h0Uf3jan7ZiA9N8z3mf6pwEhVPQSQ5DpgNWDoP0fM9M1g+/YHWLHin42p+yYhDUaqav6eLHkzsKqq/lN7/HbgVVV1Yd8ya4HRVPmnwIMH8VSLgR8eYnMXGo/JWB6TsTwmYz0Xj8nyqloy3oxn3dU7VbUeOKRLR5IMV9XQLDVpQfCYjOUxGctjMtZCOybzffXOLuCEvsfHt5okaR7Md+hvBlYkOSnJ84FzgY3z3AZJ6qx57d6pqqeSXAjcTO+SzQ1VtW0OnspfFo3lMRnLYzKWx2SsBXVM5vWLXEnSYPmLXEnqEENfkjpkwYV+klVJHkwykuSiQbdnUJI8nOTeJFuSDLfaMUk2Jdne7o8edDvnUpINSXYnua+vNu4xSM8n2+tma5JTBtfyuTHB8bg0ya72OtmS5Oy+eR9sx+PBJGcOptVzK8kJSW5Ncn+SbUne0+oL9nWyoEK/b5iHs4CTgfOSnDzYVg3U66pqZd81xhcBt1TVCuCW9nghuxpYdUBtomNwFrCi3dYCV85TG+fT1Yw9HgCXt9fJyqq6CaD93ZwLvKKt86n297XQPAW8r6pOBk4D1rV9X7CvkwUV+vQN81BV/wCMDvOgntXANW36GuCcwTVl7lXV7cDeA8oTHYPVwLXVcwdwVJKl89LQeTLB8ZjIauC6qtpfVd8HRuj9fS0oVfVYVd3dpn8KPAAsYwG/ThZa6C8DHul7vLPVuqiArya5qw1tAXBsVT3Wpn8AHDuYpg3URMegy6+dC1tXxYa+Lr/OHY8kJwKvBL7FAn6dLLTQ18+9pqpOofdxdF2S3+yfWb1rdTt9va7HAOh1T7wUWAk8Bnx8oK0ZkCRHAjcA762qn/TPW2ivk4UW+g7z0FTVrna/G/gSvY/mj49+FG33uwfXwoGZ6Bh08rVTVY9X1dNV9QzwaX7ehdOZ45HkcHqB/7mq+mIrL9jXyUILfYd5AJK8MMmLRqeBM4D76B2LNW2xNcCNg2nhQE10DDYC57erM04Dnuz7eL9gHdAf/SZ6rxPoHY9zkxyR5CR6X1zeOd/tm2tJAlwFPFBVn+ibtXBfJ1W1oG7A2cB3ge8BFw+6PQM6Br8M3NNu20aPA/BielcibAf+Bjhm0G2d4+PwBXpdFv+PXt/rBRMdAyD0rvz6HnAvMDTo9s/T8fhs29+t9AJtad/yF7fj8SBw1qDbP0fH5DX0um62Alva7eyF/DpxGAZJ6pCF1r0jSZqEoS9JHWLoS1KHGPqS1CGGviR1iKGveZGkkny87/H7k1w6S9u+OsmbZ2NbUzzPW5I8kOTWOdr+6Un+1VxsWxpl6Gu+7Ad+O8niQTekX5KZ/MvQC4D/XFWvm6PmnA4Y+ppThr7my1P0/tfo7x0448Az9ST72v3pSb6e5MYkDyX5aJJ/n+TO9r8CXtq3md9KMpzku0n+TVt/UZI/TLK5DSj2zr7t/q8kG4H7x2nPeW379yX5WKv9Ab0f8lyV5A8PWH5pktvbePT3JfmNVj8jyd8muTvJn7XxXUb/18GHWv3eJC9vg329C/i9tp3fSLIkyQ2t/ZuTvLqtf2kbHO22dlx+t68t57d9vSfJZ1ttou28Nj8fR//bo7/i1gI36F+HeevGDdgH/CLwMPBLwPuBS9u8q4E39y/b7k8HfgwsBY6gN8bJh9q89wB/1Lf+X9M7iVlB79emL6A33vl/a8scAQwDJ7Xt/h/gpHHaeRzwd8AS4DDga8A5bd5tjPMLTOB9/PxXz4uAFwGLgduBF7b6B4A/aNMPA+9u078DfKZNXwq8v2+7n6c3cB7AS+gNFTC63P9u+7QY+BFwOL2x778LLG7LHTPFdv4SeHWbPhI4bNCvE29zf5vJR1vpkFTVT5JcC/wu8H+nudrmamObJPke8NVWvxfo72a5vnqDhm1P8hDwcnpjDv2Lvk8Rv0TvTeEfgDurN078gX4NuK2q9rTn/Bzwm8BfTNZGYEMbuOsvqmpLktfS+0c+3+wN78Lzgb/tW2d0YK+7gN+eYLu/BZzc1gf4xdFPC8BfVdV+YH+S3fSG/n098GdV9UOAqto7xXa+CXyi7eMXq2rnJPuoBcLQ13z7I+Bu4E/7ak/RuhqTPI9eQI7a3zf9TN/jZ/jHr98DxxMpeuOkvLuqbu6fkeR0emf6s6Kqbk9v6Op/DVyd5BPAE8CmqjpvgtVG9+NpJv47fB5wWlX9fX+xhXf/cZlsGxNuB/hokr+iN9bMN5OcWVXfmWQ7WgDs09e8amef19P7UnTUw8C/bNP/ll5XxUy9JcnzWj//L9MbJOxm4L+0M3CSvCy9UUcncyfw2iSL0/v3gOcBX59shSTLgcer6tPAZ4BTgDuAVyf5lbbMC5O8bIrn/im9rqFRXwXe3fc8K6dY/2v0jsOL2/LHTLadJC+tqnur6mP0Pq28fIrtawEw9DUIH6fXFz3q0/SC9h7g1zm4s/C/oxfYXwHe1c5qP0Pvi9q70/tn4H/CFJ9uW1fSRcCt9EYpvauqphqC+nTgniTfBv4d8Mete+g/AF9IspVe185UofqXwJtGv8il1w021L6YvZ/eF72TtX0bcBnw9XYsR4cKnmg7721fPG+lN/LmV6ZonxYAR9mUpA7xTF+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalD/j9hvnBnK7i54wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "sns.distplot(RadPath_analysis['Number of sentences'], hist=True, kde=False, \n",
    "             color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the note_texts to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbasu/.local/share/virtualenvs/debraj_notebook-uSskSi2b/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "RadPath_analysis['note_text'] = RadPath_analysis['note_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the record with one sentence : 2413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2413, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RadPath_analysis[RadPath_analysis['Number of sentences'] ==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique number of records with size of text equal to one sentence: 746\n",
    "### Approximately one third are repeated and therefore a high chance that they may not useful (hypothesis)\n",
    "### We save these unique texts in a text file and will request domain expert intervention to evaluate the importance of those texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = RadPath_analysis[RadPath_analysis['Number of sentences'] ==1]['note_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('RadPath_notes.txt', A, fmt='%s', delimiter=',', newline=\"\\n------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with QUICKUMLS output for any useful concept from these notes containing only one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RadPath_analysis_singleSent = RadPath_analysis[RadPath_analysis['Number of sentences'] ==1]\n",
    "RadPath_analysis_singleSent =RadPath_analysis_singleSent.assign(**{'T023 output': np.nan, 'T191 output': np.nan})\n",
    "RadPath_analysis_singleSent.reset_index(inplace= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check if concept extraction is useful from semstring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_T023_total = []\n",
    "corpus_T191_total = []\n",
    "for i in range(len(RadPath_analysis_singleSent.index)):\n",
    "    \n",
    "    text = RadPath_analysis_singleSent.iloc[i].nlp_text_qu_ner\n",
    "    d = ast.literal_eval(text)\n",
    "    Testframe = pd.DataFrame.from_dict(d)\n",
    "    corpus_T023 = Testframe[Testframe['semtypestring'] == 'T023']['ngram'].tolist()\n",
    "    corpus_T191 = Testframe[Testframe['semtypestring'] == 'T191']['ngram'].tolist()\n",
    "    corpus_T023_total.append(corpus_T023)\n",
    "    corpus_T191_total.append(corpus_T191)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of the outputs are empty\n",
    "### 94% for T023\n",
    "### 91% for T191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.42146705346043"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_T023_total\n",
    "T023 = [e for e in corpus_T023_total if e]\n",
    "100*(1- (len(T023)/len(corpus_T023_total)))\n",
    "\n",
    "T191 = [e for e in corpus_T191_total if e]\n",
    "100*(1- (len(T191)/len(corpus_T191_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RadPath_analysis_singleSent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of records with 2 sentences : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RadPath_analysis[RadPath_analysis['Number of sentences'] ==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RadPath_analysis[RadPath_analysis['Number of sentences'] ==10]['note_text'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior to biopsy prior to biopsy\n"
     ]
    }
   ],
   "source": [
    "data = RadPath_analysis.loc[142]['note_text']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RadSenLen = np.array(RadSenLen)\n",
    "plt.hist(RadSenLen, 50, density= True)  # arguments are passed to np.histogram\n",
    "plt.show()\n",
    "#plt.title(\"Histogram with 'auto' bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec model from the words in the sentences\n",
    "### word vectorization with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_TFIDF = TfidfVectorizer()\n",
    "vectorizer_CV = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cohort =[]\n",
    "for i in range(len(RadPath_analysis_singleSent.index)):\n",
    "    text = RadPath_analysis_singleSent.loc[i,'note_text']\n",
    "    text_cohort.append(text)\n",
    "#     word_input = word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     text_CV= vectorizer_CV.fit_transform(word_input)\n",
    "#     text_TFIDF = vectorizer_TFIDF.fit_transform(word_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TFIDF method to find out the words that has propotional representation in he corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_CV= vectorizer_CV.fit_transform(text_cohort)\n",
    "text_TFIDF = vectorizer_TFIDF.fit_transform(text_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_CV.get_feature_names()[np.sum(text_CV.toarray(),axis =0).argmax()]\n",
    "vectorizer_TFIDF.get_feature_names()[np.sum(text_TFIDF.toarray(),axis =0).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.15397012, 0.88261424, 1.24303263, ..., 0.41588321, 0.49862795,\n",
       "       1.67012404])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(text_TFIDF.toarray(),axis =0)\n",
    "#np.sum(text_CV.toarray(),axis =0)\n",
    "# vectorizer_TFIDF.get_feature_names()[np.sum(text_TFIDF.toarray(),axis =0).argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement word2vec on th text cohort from the single sentence sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cohort\n",
    "all_words = [nltk.word_tokenize(sent) for sent in text_cohort]\n",
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_model = Word2Vec(all_words, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = word2vec_model.wv.vocab\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = word2vec_model.wv['test']\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbasu/.local/share/virtualenvs/ucd-ri-csnlp-AG0bO8yr/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "f_name = 'wor2vec_model.txt'\n",
    "word2vec_model.wv.save_word2vec_format(f_name, binary = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement doc2vec on the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-0.01174802  0.01892567  0.02331458 -0.0161646  -0.00370456 -0.00297765\n",
      "  0.01032512  0.01855865 -0.03251955 -0.01637637  0.00291244  0.01132154\n",
      "  0.02957965  0.0085325   0.01903096  0.01427311  0.00820519 -0.01913295\n",
      "  0.01544167  0.00314951]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbasu/.local/share/virtualenvs/ucd-ri-csnlp-AG0bO8yr/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 s, sys: 135 ms, total: 4.48 s\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SpaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RadSenLen =[]\n",
    "for i in RadPath_df.index:\n",
    "    text =RadPath_df.loc[i]['note_text']\n",
    "    doc = nlp(text)\n",
    "    RadSenLen.append(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the indices of rows with number of sentences equal to 1\n",
    "res_list = list(filter(lambda x: RadSenLen[x] == 3, range(len(RadSenLen)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.choice(res_list)\n",
    "print(i)\n",
    "text =RadPath_df.iloc[i]['note_text']\n",
    "doc = nlp(text)\n",
    "for i, token in enumerate(doc):\n",
    "    print('-->Sentence %d: %s' % (i, token))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
